@InProceedings{PAML1,
author="Malle, Bernd
and Kieseberg, Peter
and Weippl, Edgar
and Holzinger, Andreas",
editor="Buccafurri, Francesco
and Holzinger, Andreas
and Kieseberg, Peter
and Tjoa, A Min
and Weippl, Edgar",
title="The Right to Be Forgotten: Towards Machine Learning on Perturbed Knowledge Bases",
booktitle="Availability, Reliability, and Security in Information Systems",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="251--266",
abstract="Today's increasingly complex information infrastructures represent the basis of any data-driven industries which are rapidly becoming the 21st century's economic backbone. The sensitivity of those infrastructures to disturbances in their knowledge bases is therefore of crucial interest for companies, organizations, customers and regulating bodies. This holds true with respect to the direct provisioning of such information in crucial applications like clinical settings or the energy industry, but also when considering additional insights, predictions and personalized services that are enabled by the automatic processing of those data. In the light of new EU Data Protection regulations applying from 2018 onwards which give customers the right to have their data deleted on request, information processing bodies will have to react to these changing jurisdictional (and therefore economic) conditions. Their choices include a re-design of their data infrastructure as well as preventive actions like anonymization of databases per default. Therefore, insights into the effects of perturbed/anonymized knowledge bases on the quality of machine learning results are a crucial basis for successfully facing those future challenges. In this paper we introduce a series of experiments we conducted on applying four different classifiers to an established dataset, as well as several distorted versions of it and present our initial results.",
isbn="978-3-319-45507-5"
}

@InProceedings{PAML2,
author="Malle, Bernd
and Kieseberg, Peter
and Holzinger, Andreas",
editor="Holzinger, Andreas
and Kieseberg, Peter
and Tjoa, A Min
and Weippl, Edgar",
title="DO NOT DISTURB? Classifier Behavior on Perturbed Datasets",
booktitle="Machine Learning and Knowledge Extraction",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="155--173",
abstract="Exponential trends in data generation are presenting today's organizations, economies and governments with challenges never encountered before, especially in the field of privacy and data security. One crucial trade-off regulators are facing regards the simultaneous need for publishing personal information for the sake of statistical analysis and Machine Learning in order to increase quality levels in areas like medical services, while at the same time protecting the identity of individuals. A key European measure will be the introduction of the General Data Protection Regulation (GDPR) in 2018, giving customers the `right to be forgotten', i.e. having their data deleted on request. As this could lead to a competitive disadvantage for European companies, it is important to understand which effects deletion of significant data points has on the performance of ML techniques. In a previous paper we introduced a series of experiments applying different algorithms to a binary classification problem under anonymization as well as perturbation. In this paper we extend those experiments by multi-class classification and introduce outlier-removal as an additional scenario. While the results of our previous work were mostly in-line with our expectations, our current experiments revealed unexpected behavior over a range of different scenarios. A surprising conclusion of those experiments is the fact that classification on an anonymized dataset with outliers removed in beforehand can almost compete with classification on the original, un-anonymized dataset. This could soon lead to competitive Machine Learning pipelines on anonymized datasets for real-world usage in the marketplace.",
isbn="978-3-319-66808-6"
}

@InProceedings{FedPaper,
author="Malle, Bernd
and Giuliani, Nicola
and Kieseberg, Peter
and Holzinger, Andreas",
editor="Holzinger, Andreas
and Kieseberg, Peter
and Tjoa, A Min
and Weippl, Edgar",
title="The More the Merrier - Federated Learning from Local Sphere Recommendations",
booktitle="Machine Learning and Knowledge Extraction",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="367--373",
abstract="With Google's Federated Learning {\&} Facebook's introduction of client-side NLP into their chat service, the era of client-side Machine Learning is upon us. While interesting ML approaches beyond the realm of toy examples were hitherto confined to large data-centers and powerful GPU's, exponential trends in technology and the introduction of billions of smartphones enable sophisticated processing swarms of even hand-held devices. Such approaches hold several promises: 1. Without the need for powerful server infrastructures, even small companies could be scalable to millions of users easily and cost-efficiently; 2. Since data only used in the learning process never need to leave the client, personal information can be used free of privacy and data security concerns; 3. Since privacy is preserved automatically, the full range of personal information on the client device can be utilized for learning; and 4. without round-trips to the server, results like recommendations can be made available to users much faster, resulting in enhanced user experience. In this paper we propose an architecture for federated learning from personalized, graph based recommendations computed on client devices, collectively creating {\&} enhancing a global knowledge graph. In this network, individual users will `train' their local recommender engines, while a server-based voting mechanism aggregates the developing client-side models, preventing over-fitting on highly subjective data from tarnishing the global model.",
isbn="978-3-319-66808-6"
}

@ARTICLE{Need4Speed,
   author = {{Malle}, B. and {Giuliani}, N. and {Kieseberg}, P. and {Holzinger}, A.
	},
    title = "{The Need for Speed of AI Applications: Performance Comparison of Native vs. Browser-based Algorithm Implementations}",
  journal = {arXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1802.03707},
 primaryClass = "cs.AI",
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering, Statistics - Machine Learning},
     year = 2018,
    month = feb,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180203707M},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{InteractiveAnonymization,
  title={Interactive Anonymization for Privacy aware Machine Learning},
  author={Malle, Bernd and Kieseberg, Peter and Holzinger, Andreas},
  journal={IAL@ ECML PKDD 2017},
  pages={15},
  year={2017}
}

